{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jqTvJFHa_WD"
      },
      "source": [
        "#Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "F7IXj9uR5qe6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "294df994-e62b-41b2-b456-eed4c5b7649f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: You must give at least one requirement to install (see \"pip help install\")\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "j2ad6p43Wmgw"
      },
      "outputs": [],
      "source": [
        "!pip install -q SpeechRecognition pydub gradio PyPDF2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "UcU2IgLYbBvK"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "import torch\n",
        "import warnings\n",
        "\n",
        "from transformers import pipeline\n",
        "import PyPDF2\n",
        "import re\n",
        "\n",
        "import speech_recognition as sr\n",
        "from pydub import AudioSegment\n",
        "from pydub.silence import split_on_silence\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "import gradio as gr\n",
        "from pathlib import Path\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "7vpm2qmgbOGd",
        "outputId": "4db7ec63-7f58-4058-e61d-c204ae9913b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/.shortcut-targets-by-id/1kBsikYvE9HO3QWRWOQCMZ3wDGrZxlstE/GDSC AI HACK - Hackattoni'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "drive.mount('/content/drive')\n",
        "path = 'GDSC AI HACK - Hackattoni'\n",
        "\n",
        "os.chdir(f'/content/drive/MyDrive/{path}')\n",
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3S_XU0a9a5KV"
      },
      "source": [
        "#PDF-to-TXT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "XNtqty1g5HwK"
      },
      "outputs": [],
      "source": [
        "def split_pdf_phrases(pdf_path):\n",
        "    # Open the PDF file\n",
        "    with open(pdf_path, 'rb') as file:\n",
        "        # Create a PDF file reader object\n",
        "        reader = PyPDF2.PdfReader(file)\n",
        "\n",
        "        # Initialize an empty list to store phrases\n",
        "        phrases = []\n",
        "\n",
        "        # Iterate through each page in the PDF\n",
        "        for page_num in range(len(reader.pages)):\n",
        "            # Extract text from the page\n",
        "            page_text = reader.pages[page_num].extract_text()\n",
        "\n",
        "            # Split text into phrases based on punctuation marks or line breaks\n",
        "            # You can adjust this regular expression to fit your specific needs\n",
        "            page_phrases = re.split(r'[.!?]\\s*', page_text)\n",
        "\n",
        "            # Remove empty phrases\n",
        "            page_phrases = [phrase.strip().replace('\\n','') for phrase in page_phrases if phrase.strip()]\n",
        "\n",
        "            # Add page phrases to the list of all phrases\n",
        "            phrases.extend(page_phrases)\n",
        "\n",
        "    return phrases"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpQv0Yg8belV"
      },
      "source": [
        "#Speech-to-TXT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "IWaLuN78V--J"
      },
      "outputs": [],
      "source": [
        "r = sr.Recognizer()\n",
        "\n",
        "def transcribe_audio(chunk):\n",
        "    text = \"\"\n",
        "    audio = sr.AudioData(chunk.raw_data, chunk.frame_rate, 2)\n",
        "    text = r.recognize_google(audio)\n",
        "    return text\n",
        "\n",
        "def process_chunk(chunk, index):\n",
        "    try:\n",
        "        text = transcribe_audio(chunk)\n",
        "    except sr.UnknownValueError as e:\n",
        "        return \"\"\n",
        "    else:\n",
        "        text = f\"{text.capitalize()}. \"\n",
        "        return text\n",
        "\n",
        "def get_large_audio_transcription_on_silence(path):\n",
        "    sound = AudioSegment.from_file(path)\n",
        "    chunks = split_on_silence(sound,\n",
        "                              min_silence_len=500,\n",
        "                              silence_thresh=sound.dBFS-14,\n",
        "                              keep_silence=0)\n",
        "\n",
        "    folder_name = \"audio-chunks\"\n",
        "    if not os.path.isdir(folder_name):\n",
        "        os.mkdir(folder_name)\n",
        "\n",
        "    whole_text = []\n",
        "    with ThreadPoolExecutor() as executor:\n",
        "        futures = []\n",
        "        for i, audio_chunk in enumerate(chunks, start=1):\n",
        "            chunk_filename = os.path.join(folder_name, f\"chunk{i}.wav\")\n",
        "            audio_chunk.export(chunk_filename, format=\"wav\")\n",
        "            futures.append(executor.submit(process_chunk, audio_chunk, i))\n",
        "\n",
        "        for future in futures:\n",
        "            if future.result() != '':\n",
        "              whole_text.append(future.result())\n",
        "\n",
        "    return whole_text"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Fact-checking"
      ],
      "metadata": {
        "id": "T2s92cS1iB3n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the device to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load a pretrained model suitable for text classification\n",
        "classifier = pipeline(\"text-classification\", model=\"roberta-large-mnli\", device=device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W5bfv8BEiD-r",
        "outputId": "246b96db-6f3f-47d5-b7cf-73203d0bfde9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Some weights of the model checkpoint at roberta-large-mnli were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def fact_check(speech_txt, pdf_txt):\n",
        "  outputs=[]\n",
        "  for s in speech_txt:\n",
        "    for p in pdf_txt:\n",
        "      input_text = f\"{p} {s}\"\n",
        "      result = classifier(input_text)\n",
        "      if result[0]['label'] == 'CONTRADICTION' :\n",
        "        outputs.append((p,s))\n",
        "  return outputs"
      ],
      "metadata": {
        "id": "RQwYrsToiFen"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHwnZ-cRuPql"
      },
      "source": [
        "#Front-END"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 660
        },
        "id": "d3LQfOFSfB9F",
        "outputId": "0c981c33-a850-47a5-e3e3-058bd532b46e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Thanks for being a Gradio user! If you have questions or feedback, please join our Discord server and chat with us: https://discord.gg/feTf9x3ZSB\n",
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://e66edd90b5df87ad32.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://e66edd90b5df87ad32.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "def process_pdf(pdf_file):\n",
        "    text = split_pdf_phrases(pdf_file)\n",
        "    return text\n",
        "\n",
        "def process_audio(audio_file):\n",
        "    # Process the audio\n",
        "    speech_txt = get_large_audio_transcription_on_silence(audio_file)\n",
        "\n",
        "    # Return the result\n",
        "    return speech_txt\n",
        "\n",
        "def process(pdf_input, audio_input):\n",
        "    pdf_txt = process_pdf(pdf_input)\n",
        "    speech_txt = process_audio(audio_input)\n",
        "\n",
        "    outputs = fact_check(speech_txt, pdf_txt)\n",
        "    real_out = \"\"\n",
        "    for c in outputs:\n",
        "      real_out += f'Your sentence: \"{c[0]}\" is in contradiction with the following sentence \"{c[1]}\"\\n'\n",
        "    return pdf_txt, speech_txt, real_out\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "\n",
        "    gr.Markdown()\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            pdf_inp = gr.File(scale=1,file_types=['.pdf'])\n",
        "            pdf_name = gr.Textbox(label=\"File uploaded\", visible=False)\n",
        "\n",
        "        with gr.Column():\n",
        "            audio_inp = gr.Audio(scale=1, type=\"filepath\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            out_pdf = gr.Textbox(\"\", label='Pdf text')\n",
        "\n",
        "        with gr.Column():\n",
        "            out_speech = gr.Textbox(\"\", label='Speech text')\n",
        "\n",
        "    with gr.Row():\n",
        "        btn = gr.Button(\"Elaborate inputs\")\n",
        "    with gr.Row():\n",
        "        out = gr.Textbox(\"output\", label='')\n",
        "\n",
        "    btn.click(fn=process, inputs=[pdf_inp,audio_inp], outputs=[out_pdf,out_speech, out])\n",
        "\n",
        "demo.launch()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}